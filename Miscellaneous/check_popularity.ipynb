{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data_by_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df = df[['popularity', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df[['popularity']],df[['year']], alpha = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install statsmodels\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = df[['popularity']]\n",
    "x = df[['year']]\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "x = df[['year']].values.tolist()\n",
    "y = df[['popularity']].values.tolist()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(x, y, s=10)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "X = x\n",
    "Y = y\n",
    "regr.fit(X, Y)  # use fit method\n",
    "r_sqr = regr.score(X, Y)\n",
    "betas = regr.coef_  # m\n",
    "y_int = regr.intercept_  # b\n",
    "\n",
    "# Visualize: actual vs. predicted income (from model)\n",
    "y_hat = betas[0] * x + y_int\n",
    "plt.plot(x, y_hat, color='orange')  # y_hat, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./full_music_data.csv')\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df = df[['popularity', 'artist_names', 'song_title (censored)', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = df['year'].values.tolist()\n",
    "\n",
    "std_c = 0.017/0.7045 + 33.210/1360.9905\n",
    "\n",
    "# simulation_func = 0.7045x - 1360.9905\n",
    "\n",
    "expected_pop = []\n",
    "\n",
    "for i in year_list:\n",
    "    simul_result = 0.7045*i - 1360.9905\n",
    "    simul_interval = [simul_result, simul_result * std_c]\n",
    "    expected_pop.append(simul_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['simulated_popularity'] = expected_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "excep_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    lst = df.at[i,'simulated_popularity']\n",
    "    count = 0\n",
    "    valid = 0\n",
    "    for t in range(100):\n",
    "        val = random.gauss(lst[0], lst[1])\n",
    "        actual_val = df.at[i,'popularity']\n",
    "        try:\n",
    "            excep = -val + actual_val\n",
    "            count += excep\n",
    "            valid += 1\n",
    "        except:\n",
    "            excep = 'nan'\n",
    "    excep_list.append(count/valid)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-discrimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sig'] = excep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df.sort_values(by = ['sig'], ascending = False)\n",
    "df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df = df[df['sig'] != np.inf]\n",
    "df = df[df['sig'] != -np.inf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['popularity'] > 10].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-vanilla",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./reverseTrend.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_by_artist.csv')\n",
    "df2 = pd.read_csv('full_music_data.csv')\n",
    "df3 = df2\n",
    "df3 = df3.drop_duplicates(subset='artist_names', keep='first', inplace=False)\n",
    "df3\n",
    "print('===')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import scipy.stats as st\n",
    "\n",
    "all_artist = df3['artist_names'].values.tolist()\n",
    "expand_artist = []\n",
    "for i in all_artist:\n",
    "    lst = eval(i)\n",
    "    for j in lst:\n",
    "        expand_artist.append(j)\n",
    "re_expand_artist = sorted(set(expand_artist),key=expand_artist.index)\n",
    "\n",
    "year_coll = []\n",
    "for i in re_expand_artist:\n",
    "    sing_coll = []\n",
    "    for j in range(len(df2)):\n",
    "        if i in df2.at[j,'artist_names']:\n",
    "            sing_coll.append(df2.at[j, 'year'])\n",
    "    sing_coll = np.array(sing_coll)\n",
    "\n",
    "    loc=np.mean(sing_coll)\n",
    "    scale=st.sem(sing_coll)\n",
    "        \n",
    "    if scale == 0 or len(sing_coll) == 1:\n",
    "        conf_interval = [int(loc), int(loc)]\n",
    "    else:\n",
    "        conf_interval = list(st.norm.interval(alpha=0.90, loc=np.mean(sing_coll), scale=st.sem(sing_coll)))\n",
    "    print(i)\n",
    "    print(sing_coll)\n",
    "    print(conf_interval)\n",
    "    year_coll.append(conf_interval)\n",
    "    \n",
    "#     print(i)\n",
    "#     print(sing_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re_expand_artist[0], year_coll[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_intv_coll = []\n",
    "\n",
    "for the_year in year_coll:\n",
    "    std_c = 0.017/0.7045 + 33.210/1360.9905\n",
    "    lower_exp = 0.7045*the_year[0] - 1360.9905\n",
    "    upper_exp = 0.7045*the_year[1] - 1360.9905\n",
    "    expected_pop = [lower_exp, upper_exp]\n",
    "    year_intv_coll.append(expected_pop)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_intv_coll[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['artist'] = re_expand_artist\n",
    "df['expected_popularity'] = year_intv_coll\n",
    "df['average_working_year'] = year_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data by artist\n",
    "df4 = pd.read_csv('data_by_artist.csv')\n",
    "df['actual_popularity'] = np.nan\n",
    "loc = 0\n",
    "for i in df['artist']:\n",
    "    print(i, df.at[loc, 'artist'])\n",
    "    for k in range(len(df4)):\n",
    "        if df4.at[k,'artist_name'] == i:\n",
    "            df.at[loc, 'actual_popularity'] = df4.at[k,'popularity']\n",
    "    loc += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pop_exp_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pdd = pd.read_csv('pop_exp_sim.csv')\n",
    "pdd['mean'] = ''\n",
    "pdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in pdd['expected_popularity']:\n",
    "    print(i)\n",
    "    mean = (eval(i)[0] + eval(i)[1])/2\n",
    "    pdd.at[count,'mean'] = mean\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdd)):\n",
    "    pdd.at[i,'diff'] = pdd.at[i,'actual_popularity'] - pdd.at[i,'mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdd = pdd.sort_values(by = ['diff'], ascending = False)\n",
    "pdd.to_csv('random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd = pd.read_csv('betweeness.csv', encoding='unicode_escape')\n",
    "pddd['working year'] = ''\n",
    "pddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in pddd['Artist']:\n",
    "    for j in range(len(pdd)):\n",
    "        if pdd.at[j, 'artist'] == i:\n",
    "            pddd.at[count, 'working year'] = pdd.at[j, 'average_working_year']\n",
    "    print(count)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(pddd)):\n",
    "    try: \n",
    "        kk = pddd.at[i, 'working year']\n",
    "        pddd.at[i, 'working year'] = kk * (-0.02643606442739991) + 54.58391785656113\n",
    "    except SyntaxError: \n",
    "        pddd.at[i, 'working year'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "for i in range(0, len(pddd)):\n",
    "    try: \n",
    "        kk = pddd.at[i, 'working year']\n",
    "        pddd.at[i, 'working year'] = math.log(kk)\n",
    "    except SyntaxError: \n",
    "        pddd.at[i, 'working year'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd['updated_1'] = ''\n",
    "for i in range(len(pddd)):\n",
    "    pddd.at[i,'updated_1'] = pddd.at[i,'betweeness'] * pddd.at[i,'working year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd.sort_values(by = ['updated_1'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd = pd.read_csv('updated_1.csv')\n",
    "pddd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "pf = pddd[['updated_1']].apply(max_min_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "pddd['updated_1'] = pf\n",
    "pddd.to_csv('updated_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "influ_file = pd.read_csv('influence.csv', encoding='unicode_escape')\n",
    "updated_1 = pd.read_csv('updated_1.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "\n",
    "pf = influ_file[['Influence Index']].apply(max_min_scaler)\n",
    "influ_file['norm_index'] = pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "influ_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(updated_1)):\n",
    "    the_artist = updated_1.at[i, 'Artist']\n",
    "    for j in range(len(influ_file)):\n",
    "        if the_artist == influ_file.at[j, 'Artist']:\n",
    "            updated_1.at[i, 'norm_influ_index'] = influ_file.at[j, 'norm_index']\n",
    "            print(the_artist)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for i in range(len(updated_1)):\n",
    "    updated_1.at[i,'updated_2'] = updated_1.at[i,'updated_1'] * math.log(updated_1.at[i,'norm_influ_index'] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = updated_1[['updated_2']].apply(max_min_scaler)\n",
    "updated_1['norm_updated_2'] = pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1.drop(columns = ['updated_2'])\n",
    "updated_1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1 = updated_1.sort_values(by = ['norm_updated_2'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_1.to_csv('updated_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
